# Credit-Risk Project

The goal of the project is to predict the risk of financial failure based on historical data. 

Banks and financial organizations use the historical data on customers' behaviour to predict the probability of future 
defaults of credit card borrowings. 

Banks can use credit risk prediction to decide whether to issue a credit card to the applicant.

## Data Sets
for this project, we have 2 different datasets:

* **Application Records**: all data related to the demographic information of applicants
* **Credit Records**: historical credit card status of each applicant

Applicant ID is a primary key to joining datasets.

## Project Phases
The project was led in 2 major phases:
* Exploratory Data Analytics: 1) Data Cleaning, 2) Feature engineering
* Predictive modeling

## Feature Engineering
A label indicating delinquency occurrences 3 months in advance can be generated by considering the account history and status of each individual account.
<br />
![image](https://user-images.githubusercontent.com/53322705/221474113-c96cfb7f-5465-4b4e-aa60-577a1cd5c5e3.png)
<br>
<br />
The dat set containes an imbalanced label:
<br />
![image](https://user-images.githubusercontent.com/53322705/221483521-9d2f9feb-4d2e-4e3d-819c-325d9839cd63.png)
<br>
<br />
Therefore, we applied under sampling technique for the model training.
<br>
## Correlations
We performed a correlation analysis to assess the relationship between the features and the label prior to building the model:

![image](https://user-images.githubusercontent.com/53322705/221487675-5a73bc68-3908-4e3e-9fe7-1ff63b96efe2.png)

## Modeling
Developed 3 major predictive models:
* Random Forest
* XGBOOST
* CATBOOST

## Results	
The model metrics are saved in a table for a fast and clear comparison:

|NO|Model             | accuracy_score | precision_score | recall_score   | roc_auc_score| f1_score|
|- | -----------------| -------------- | --------------  | -------------- | -------------| --------|
|1 |randomforest_Final|   0.864091     |     0.888571    |   0.678404     |   0.817851   |0.769394 |
|2 |xgboost_model_fin |   0.781087     |     0.952576    |   0.363041     |   0.676985   |0.525722 |
|3 |ctboost_model_fin |   0.867162     |     0.921760    |   0.658228     |   0.815100   |0.768016 |

Catboost model has a better performance to predict high-risk applicants. Since we have an imbalanced data,
 the recall score can be an important metric for this project. Catboost has the highest precision and recall scores.
